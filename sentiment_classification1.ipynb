{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits\n",
    "import string\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import Imputer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset=pd.read_csv('datasets/tow_classes_tweet.csv', encoding='utf-8', usecols=['sentiment', 'txt'])\n",
    "dataset1=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/LABR/ATT.csv', encoding='utf-8',usecols=['text', 'polarity'])\n",
    "dataset1.columns = ['txt', 'sentiment']\n",
    "dataset1=clean(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/LABR/HTL.csv', encoding='utf-8',usecols=['text', 'polarity'])\n",
    "dataset2.columns = ['txt', 'sentiment']\n",
    "dataset2=clean(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/LABR/HTL.csv', encoding='utf-8',usecols=['text', 'polarity'])\n",
    "dataset2.columns = ['txt', 'sentiment']\n",
    "dataset2=clean(dataset2)\n",
    "\n",
    "dataset3=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/LABR/MOV.csv', encoding='utf-8',usecols=['text', 'polarity'])\n",
    "dataset3.columns = ['txt', 'sentiment']\n",
    "dataset3=clean(dataset3)\n",
    "\n",
    "dataset4=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/LABR/PROD.csv', encoding='utf-8',usecols=['text', 'polarity'])\n",
    "dataset4.columns = ['txt', 'sentiment']\n",
    "dataset4=clean(dataset4)\n",
    "\n",
    "dataset5=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/LABR/RES.csv', encoding='utf-8',usecols=['text', 'polarity'])\n",
    "dataset5.columns = ['txt', 'sentiment']\n",
    "dataset5=clean(dataset5)\n",
    "\n",
    "dataset6=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/LABR/RES1.csv', encoding='utf-8',usecols=['text', 'polarity'])\n",
    "dataset6.columns = ['txt', 'sentiment']\n",
    "dataset6=clean(dataset6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.concat([dataset1, dataset2, dataset3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    10775\n",
       "-1     2647\n",
       " 0     2150\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     المكان الذي يمكنك فيه مراجعه الذات والتفكر هو ...\n",
       "1     موقع راءع وحديقه راءعه ويستحق نجمه اضافيه علي ...\n",
       "2     اسوا فندق اقمت فيه علي الاطلاق يستغرق تسجيل ال...\n",
       "3     بدون روح كانه فندق ثلاثه نجوم بدون اداره احترا...\n",
       "4     فندق جميل مع سوء الاداره والخدمات من الخارج بد...\n",
       "5     فندق جميل، منظر راءع من بركه السباحه علي السطح...\n",
       "6     مكان لطيف وهادء بعيدا عن الزحام عثرت علي هذا ا...\n",
       "7     راقي و كلاسيكي فندق كبير مصم بفن الديكور الجمي...\n",
       "8     تحذير لرجال الذي يحبون تناول بعض البيره ليلا ش...\n",
       "9     فندق راءع بعد ايام قضيناها في ليسبوا، وصلنا اخ...\n",
       "10    ساحر اذا كنت توق الي تجربه فريده، عليك بتجربه ...\n",
       "11    هناك بعض الاحباطات ولكن الغرف كانت راءعه والمو...\n",
       "12    ينصح به لغايه لساءحين من اصحاب الميزانيات المن...\n",
       "13    لطيف لغايه الموقع منقطع النظيرفريق العمل ودود ...\n",
       "14    فندق راءع جدا وانصح به فندق فخم وحديث كبير جدا...\n",
       "15    فندق راءع فريق عمل ودود وافطار جيد ليس لدي سوي...\n",
       "16    اسوا خدمه عملاء الفندق نفسه جميل فيما عدا ذلك،...\n",
       "17    فندق من فءه نجمه واحده يصنف باربعه الفندق قديم...\n",
       "18    الفندق لطيف ولكن الطعام كان فظيعا كان فندقا جم...\n",
       "19    عطله جيده، ولكنه فندق نجوم وليس نجوم عدنا لتو ...\n",
       "20    فندق راءع عدنا لتو من اقامه لمده ثمانيه ايام ف...\n",
       "21    طعام رديء هذا الفندق تحتاج الي تغير في الاداره...\n",
       "22    فندق راءع وموقع راءع اقمنا في هذا الفندق الجمي...\n",
       "23    مكان راءع ولطيف ذهبت الي هناك في نهايه اغسطس و...\n",
       "24    قليل من حالات الفواق ولكنا نخط لعوده مره اخري ...\n",
       "25    قيمه مقابل المال قيمه جيده مقابل المال لم يكن ...\n",
       "26    رهيب هذا الفندق لم يشهد اي طبقه من الطلاء او ا...\n",
       "27    العاءلات عليكم توخي الحذر اذا كان ستسافر مع عا...\n",
       "28    قيمه متازه لمال لا يمكني ان افهم التقيمات السي...\n",
       "29    جيد بشكل مذهل لقد ذهبنا في اسبوع عطله عاءليه ل...\n",
       "                            ...                        \n",
       "70    ‪ ‬ فندق جيد جدا سعره رخيص داخل المدينه مصوع م...\n",
       "71    بدل ما مندفع مصاري عشان نبسط صرنا ندفع مصاري ع...\n",
       "72    موقع متاز الخدمه متاز الاستقبال كان جميل العام...\n",
       "73    استمتعت جدا كنت في اجازه مع زوجتي و عندما وصلا...\n",
       "74    فندق مناسب جدا في حي راءع قيمه راءعه بغض النظر...\n",
       "75    متاز انا لم اسكن به فلاكن من الصور التي شاهدته...\n",
       "76    المكان يحتاج الي التجديد الموقع متاز، حيث يقع ...\n",
       "77    اكثر مكان مريح في تل ابيب نزل اولد جافا يمكن ا...\n",
       "78    لطيف لكن يجب ابعاد موظف الاستقبال عن المكان شع...\n",
       "79    لا يوجد طعام حجزنا فطور وعشاء لكن وقت وجبه الع...\n",
       "80     لقد كنت بالفندق وقم استقلالي بحفاوه والمشروب ...\n",
       "81     ناصر هو الفندق انه شخص جيد في الاستقبال اني ا...\n",
       "82    متناغم ومضياف فعلا استمتعت باقامتنا لمده ليال ...\n",
       "83    زياره متازه سنعود مره اخري وسنوصي به نظيف جدا،...\n",
       "84    لطيف و قريب من المدينه القديمه الغرف مرتبه، نظ...\n",
       "85    موقع راءع بالتاكسي او دقيقه سيرا علي الاقدام ا...\n",
       "86    السعوديه من اجمل واهدا الفنادق التي سكنتها بال...\n",
       "87    فندق جميل فندق جميل و راءع و افضل شيء عجبني با...\n",
       "88    راءع بعض الغرف راءعه وجبه الافطار كانت ايضا لا...\n",
       "89    فندقفي قمه الروعه فندق حلو بصراحه فيه خدمات وم...\n",
       "90    اجما وافخم مكان في صنعاء فندق البستان من افخم ...\n",
       "91    نقاش الشباب حول مءتمر الحوار الوطني والقضيه ال...\n",
       "92    تجربه جميله تقريبا من افضل الفنادق في صنعا خصو...\n",
       "93    احلي فندق جلسه فيه الفندق فخم فيه والاستقبال ح...\n",
       "94    حلو اذا كان غير مزحوم فندق راءع من حيث الموقع ...\n",
       "95    مكان مريح ولطيف لغايه يضم اشخاصا ودودين ولكن ا...\n",
       "96    المتعه الحقيقيه ان السكن في روشا ارجان له متعه...\n",
       "97    فندق راقي وسعره مقبول فندق راقي من فءه الخمس ن...\n",
       "98    الجمال والمتعه انصح بزياره فندق روتانا ارجان ا...\n",
       "99    احلي ناس بعد التحيه اشكر فريق الاستقبال في ارج...\n",
       "Name: txt, Length: 100, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.txt.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train, twenty_test = train_test_split(dataset, test_size=0.1)\n",
    "#twenty_train.tail(500)\n",
    "#prints all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3864"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1941\n",
       "0    1923\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    224\n",
       "1    206\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "# Removing stop words\n",
    "def get_stop_words(path):\n",
    "    #\"stop_words.txt\"\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "stop_words = get_stop_words('Arabic_stop_word.txt')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words)), ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_counts.shape (3864, 16645)\n",
      "X_train_tfidf.shape (3864, 16645)\n"
     ]
    }
   ],
   "source": [
    "    # Extracting features from text files\n",
    "    count_vect = CountVectorizer(stop_words=stop_words)\n",
    "    X_train_counts = count_vect.fit_transform(twenty_train['txt'])\n",
    "    print('X_train_counts.shape', X_train_counts.shape)\n",
    "    # TF-IDF\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    print ('X_train_tfidf.shape',X_train_tfidf.shape)\n",
    "    \n",
    "    # Training Naive Bayes (NB) classifier on training data.\n",
    "    clf = MultinomialNB().fit(X_train_tfidf, twenty_train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.827906976744186"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
    "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
    "# We will be using the 'text_clf' going forward.\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train['txt'], twenty_train.sentiment)\n",
    "predicted = text_clf.predict(twenty_test['txt'])\n",
    "np.mean(predicted == twenty_test.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB [0.827906976744186, 0.8278138528138528, 0.8238095238095239, 0.8084112149532711, 0.8398058252427184]\n"
     ]
    }
   ],
   "source": [
    "        y_pred = predicted\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"NB\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372093023255814\n",
      "Enhanced NB [0.8372093023255814, 0.8371952142965319, 0.8356807511737089, 0.8090909090909091, 0.8640776699029126]\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))), ('tfidf', TfidfTransformer(use_idf=False)), ('clf', MultinomialNB(alpha=1e-1))])\n",
    "text_clf = text_clf.fit(twenty_train['txt'], twenty_train.sentiment)\n",
    "# Performance of NB Classifier\n",
    "predicted = text_clf.predict(twenty_test['txt'])\n",
    "print(np.mean(predicted == twenty_test.sentiment))\n",
    "def accuracy():\n",
    "        y_pred = predicted\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\"Enhanced NB\",results)\n",
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 3)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-4)}\n",
    "# Next, we create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "# To see the best mean score and the params, run the following code\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "# Output for above should be: The accuracy has now increased to ~90.6% for the NB classifier (not so naive anymore! 😄)\n",
    "# and the corresponding parameters are {‘clf__alpha’: 0.01, ‘tfidf__use_idf’: True, ‘vect__ngram_range’: (1, 2)}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7883720930232558\n",
      " SVM [0.7883720930232558, 0.782440689651338, 0.7465181058495821, 0.8758169934640523, 0.6504854368932039]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Training Support Vector Machines - SVM and calculating its performance\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.txt)\n",
    "print(np.mean(predicted_svm == twenty_test.sentiment))\n",
    "def accuracy1():\n",
    "        y_pred = predicted_svm\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\" SVM\",results)\n",
    "accuracy1()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8325581395348837"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enhanceddddddddddddd\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))), ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-4, n_iter=5, random_state=42))])\n",
    "text_clf_svm = text_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.txt)\n",
    "y_pred = predicted_svm\n",
    "y_test = twenty_test.sentiment\n",
    "accu=metrics.accuracy_score(y_test, y_pred)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced SVM [0.8325581395348837, 0.8320348950760617, 0.8238095238095239, 0.835, 0.8106796116504854]\n"
     ]
    }
   ],
   "source": [
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"Enhanced SVM\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly doing grid search for SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit sentiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8232558139534883"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NBSVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "train=twenty_train\n",
    "test=twenty_test\n",
    "import re\n",
    "import string\n",
    "re_tok = re.compile(r'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,1), tokenizer=tokenize, strip_accents='unicode', use_idf=1 )\n",
    "trn_term_doc = vec.fit_transform(train['txt'])\n",
    "test_term_doc = vec.transform(test['txt'])\n",
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "x = trn_term_doc\n",
    "test_x = test_term_doc\n",
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=4, dual=False)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r\n",
    "\n",
    "label_cols=['sentiment']\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]\n",
    "    \n",
    "\n",
    "y_test_non_category = test.sentiment\n",
    "y_predict_non_category = preds.round()\n",
    "\n",
    "y_pred = y_predict_non_category\n",
    "y_test = y_test_non_category\n",
    "f1_score = metrics.f1_score(y_test, y_pred)\n",
    "accu=metrics.accuracy_score(y_test, y_pred)\n",
    "accu\n",
    "#print('\\n Testing accuracy is {}'.format(accuracy_score(y_test_non_category, y_predict_non_category)))\n",
    "#print ('\\n F1',f1_score(y_test_non_category,y_predict_non_category, average='weighted'))\n",
    "#print ('\\n Recall:', recall_score(y_test_non_category, y_predict_non_category,average='weighted'))\n",
    "#print ('\\n Precision:', precision_score(y_test_non_category, y_predict_non_category, average='weighted'))\n",
    "#print ('\\n clasification report:\\n', classification_report(y_test_non_category, y_predict_non_category))\n",
    "#print ('\\n confussion matrix:\\n',confusion_matrix(y_test_non_category, y_predict_non_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB-SVM [0.8232558139534883, 0.8225032045015099, 0.8109452736318408, 0.8316326530612245, 0.7912621359223301]\n"
     ]
    }
   ],
   "source": [
    "        y_pred = y_predict_non_category\n",
    "        y_test = y_test_non_category\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\"NB-SVM\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-08-17 00:53:58,983] INFO: loading projection weights from arabic-news.bin\n",
      "[2018-08-17 00:54:01,651] INFO: loaded (159175, 300) matrix from arabic-news.bin\n",
      "[2018-08-17 00:54:01,651] INFO: precomputing L2-norms of word weight vectors\n",
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "[2018-08-17 00:54:03,692] INFO: Tokenizing the training dataset ..\n",
      "[2018-08-17 00:54:03,715] INFO:  ... total 47114 training tokens.\n",
      "[2018-08-17 00:54:03,715] INFO: Tokenizing the testing dataset ..\n",
      "[2018-08-17 00:54:03,731] INFO:  ... total 5132 testing tokens.\n",
      "[2018-08-17 00:54:03,731] INFO: Vectorizing training tokens ..\n",
      "[2018-08-17 00:54:03,937] INFO:  ... total 3864 training\n",
      "[2018-08-17 00:54:03,937] INFO: Vectorizing testing tokens ..\n",
      "[2018-08-17 00:54:03,967] INFO:  ... total 430 testing\n",
      "[2018-08-17 00:54:03,993] INFO: Done loading and vectorizing data.\n",
      "[2018-08-17 00:54:03,993] INFO: --- Sentiment CLASSIFIERS ---\n",
      "[2018-08-17 00:54:03,993] INFO: fitting ... \n",
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "[2018-08-17 00:54:16,698] INFO: results ...\n",
      "[2018-08-17 00:54:16,698] INFO: DONE!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMacAvg. 76.49% F1. 75.78% P. 74.88 R. 76.70 : RandomForestClassifier\n",
      "\tMacAvg. 76.45% F1. 73.82% P. 80.11 R. 68.45 : SGDClassifier\n",
      "\tMacAvg. 75.54% F1. 74.58% P. 74.40 R. 74.76 : LinearSVC\n",
      "\tMacAvg. 72.54% F1. 71.90% P. 70.56 R. 73.30 : NuSVC\n",
      "\tMacAvg. 77.83% F1. 76.54% P. 77.89 R. 75.24 : LogisticRegressionCV\n",
      "\tMacAvg. 73.52% F1. 71.25% P. 74.87 R. 67.96 : GaussianNB\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from logging import info, basicConfig, INFO \n",
    "LOG_HEAD = '[%(asctime)s] %(levelname)s: %(message)s'\n",
    "basicConfig(format=LOG_HEAD, level=INFO)\n",
    "class ArSentiment(object):\n",
    "    def __init__(self, train, test, embeddings_file=None, dataset_file=None, plot_roc=False, split=0.9, detailed=False):\n",
    "        \"\"\"\n",
    "        :param embeddings_file: path to the embeddings file.\n",
    "        :param dataset_file: path to a labeled dataset file.\n",
    "        :param plot_roc: boolean, plot ROC figure.\n",
    "        :param split: float, data split fraction i.e. train | test split (default: 90% | 10%)\n",
    "        :param detailed: boolean, output classifiers' parameters info i.e. name, parameters' value, .. etc.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_file = dataset_file\n",
    "        self.split = split\n",
    "\n",
    "        self.embeddings, self.dimension = self.load_vectors(embeddings_file)\n",
    "\n",
    "        # read dataset\n",
    "        train, test = train, test\n",
    "        train_txt, test_txt = train['txt'], test['txt']\n",
    "        self.y_train = train['sentiment']\n",
    "        self.y_test = test['sentiment']\n",
    "\n",
    "        # -- dataset preprocessing -- #\n",
    "        train_tokens = self.tokenize_data(train_txt, 'training')\n",
    "        test_tokens = self.tokenize_data(test_txt, 'testing')\n",
    "\n",
    "        # -- vectorize training/testing data -- #\n",
    "        train_vectors = self.average_feature_vectors(train_tokens, 'training')\n",
    "        test_vectors = self.average_feature_vectors(test_tokens, 'testing')\n",
    "\n",
    "        # vectorized features\n",
    "        self.X_train = self.remove_nan(train_vectors)\n",
    "        self.X_test = self.remove_nan(test_vectors)\n",
    "\n",
    "        info('Done loading and vectorizing data.')\n",
    "        info(\"--- Sentiment CLASSIFIERS ---\")\n",
    "        info(\"fitting ... \")\n",
    "\n",
    "        # classifiers to use\n",
    "        classifiers = [\n",
    "            RandomForestClassifier(n_estimators=100),\n",
    "            SGDClassifier(loss='log', penalty='l1'),\n",
    "            LinearSVC(C=1e1),\n",
    "            NuSVC(),\n",
    "            LogisticRegressionCV(solver='liblinear'),\n",
    "            GaussianNB(),\n",
    "        ]\n",
    "\n",
    "        self.accuracies = {}\n",
    "\n",
    "        # RUN classifiers\n",
    "        for c in classifiers:\n",
    "            self.classify(c, detailed, plot_roc)\n",
    "\n",
    "        avg_f1 = 0\n",
    "        info('results ...')\n",
    "        for k, v in self.accuracies.items():\n",
    "            string = '\\tMacAvg. {:.2f}% F1. {:.2f}% P. {:.2f} R. {:.2f} : {}'\n",
    "            print(string.format(v[0] * 100, v[1] * 100, v[2] * 100, v[3] * 100, k))\n",
    "            avg_f1 += float(v[1])\n",
    "\n",
    "        #print('OVERALL avg F1 test {:.2f}%'.format((avg_f1 / len(self.accuracies)) * 100))\n",
    "        info(\"DONE!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectors(model_name, binary=True):\n",
    "        \"\"\"load the pre-trained embedding model\"\"\"\n",
    "        if binary:\n",
    "            w2v_model = KeyedVectors.load_word2vec_format(model_name, binary=True)\n",
    "        else:\n",
    "            w2v_model = KeyedVectors.load(model_name)\n",
    "\n",
    "        w2v_model.init_sims(replace=True)  # to save memory\n",
    "        vocab, vector_dim = w2v_model.syn0.shape\n",
    "        return w2v_model, vector_dim\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        \"\"\"\n",
    "        :param text: a paragraph string\n",
    "        :return: a list of words\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                txt = unicode(text, 'utf-8')  # py2\n",
    "            except NameError:\n",
    "                txt = text  # py3\n",
    "            words = wordpunct_tokenize(txt)\n",
    "            length = len(words)\n",
    "        except TypeError:\n",
    "            words, length = ['NA'], 0\n",
    "\n",
    "        return words, length\n",
    "\n",
    "    def tokenize_data(self, examples_txt, type_='NaN'):\n",
    "        tokens = []\n",
    "        info('Tokenizing the {} dataset ..'.format(type_))\n",
    "        total_tokens = []\n",
    "        for txt in examples_txt:\n",
    "            words, num = self.tokenize(txt)\n",
    "            tokens.append(words)\n",
    "            total_tokens.append(num)\n",
    "        info(' ... total {} {} tokens.'.format(sum(total_tokens), type_))\n",
    "        return tokens\n",
    "\n",
    "    def feature(self, words):\n",
    "        \"\"\"average words' vectors\"\"\"\n",
    "\n",
    "        feature_vec = np.zeros((self.dimension,), dtype=\"float32\")\n",
    "        retrieved_words = 0\n",
    "        for token in words:\n",
    "            try:\n",
    "                feature_vec = np.add(feature_vec, self.embeddings[token])\n",
    "                retrieved_words += 1\n",
    "            except KeyError:\n",
    "                pass  # if a word is not in the embeddings' vocabulary discard it\n",
    "\n",
    "        np.seterr(divide='ignore', invalid='ignore')\n",
    "        feature_vec = np.divide(feature_vec, retrieved_words)\n",
    "\n",
    "        return feature_vec\n",
    "\n",
    "    def average_feature_vectors(self, examples, type_='NaN'):\n",
    "        \"\"\"\n",
    "        :param examples: a list of lists (each list contains words) e.g. [['hi','do'], ['you','see'], ... ]\n",
    "        :param type_: (optional) type of examples text e.g. train / test\n",
    "        :return: the average word vector of each list\n",
    "        \"\"\"\n",
    "\n",
    "        feature_vectors = np.zeros((len(examples), self.dimension), dtype=\"float32\")\n",
    "        info(\"Vectorizing {} tokens ..\".format(type_))\n",
    "        for i, example in enumerate(examples):\n",
    "            feature_vectors[i] = self.feature(example)\n",
    "\n",
    "        info(\" ... total {} {}\".format(len(feature_vectors), type_))\n",
    "\n",
    "        return feature_vectors\n",
    "\n",
    "    def classify(self, classifier=None, info_=False, plot_roc=False):\n",
    "\n",
    "        classifier_name = classifier.__class__.__name__\n",
    "\n",
    "        if info_:\n",
    "            info('fitting data ...')\n",
    "            info('\\n\\ncreated \\n\\n{}'.format(classifier))\n",
    "\n",
    "        classifier.fit(self.X_train, self.y_train)\n",
    "        pscore = classifier.score(self.X_test, self.y_test)\n",
    "\n",
    "        if info_:\n",
    "            info('\\n\\n\\t{}() ACCURACY: {}\\n'.format(classifier_name, pscore))\n",
    "\n",
    "        # F1 score\n",
    "        y_pred = classifier.predict(self.X_test)\n",
    "        f1_score = metrics.f1_score(self.y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(self.y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(self.y_test, y_pred)\n",
    "        precision = metrics.precision_score(self.y_test, y_pred)\n",
    "\n",
    "        results = [macc, f1_score, precision, recall]\n",
    "        self.accuracies[classifier_name] = results\n",
    "\n",
    "        # prediction\n",
    "        negative = len(classifier.predict(self.X_test)[classifier.predict(self.X_test) == 0])\n",
    "        positive = len(classifier.predict(self.X_test)[classifier.predict(self.X_test) == 1])\n",
    "\n",
    "        if plot_roc:\n",
    "            info('plotting roc of ... {}'.format(classifier_name))\n",
    "            self.plot_auc(classifier, classifier_name, negative, positive)\n",
    "\n",
    "    def plot_auc(self, estimator, estimator_name, neg, pos):\n",
    "        try:\n",
    "            classifier_probas = estimator.decision_function(self.X_test)\n",
    "        except AttributeError:\n",
    "            classifier_probas = estimator.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "        false_positive_r, true_positive_r, thresholds = metrics.roc_curve(self.y_test, classifier_probas)\n",
    "        roc_auc = metrics.auc(false_positive_r, true_positive_r)\n",
    "\n",
    "        label = '{:.1f}% neg:{} pos:{} {}'.format(roc_auc * 100, neg, pos, estimator_name)\n",
    "        plt.plot(false_positive_r, true_positive_r, label=label)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([-0.05, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.title('ROC score(s)')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right', prop={'size': 10})\n",
    "        plt.savefig(\"ROC.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.grid()\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_nan(x):\n",
    "        \"\"\"remove NaN values from data vectors\"\"\"\n",
    "        imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "        x_clean = imp.fit_transform(x)\n",
    "        return x_clean\n",
    "if __name__ == \"__main__\":\n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument(\"embeddings/arabic-news.bin\", help=\"path a pre-trained vectors model.\")\n",
    "    #parser.add_argument(\"datasets/LABR-book-reviews.csv\", help=\"path a labeled (0/1) sentiment dataset.\")\n",
    "\n",
    "    #args = parser.parse_args()\n",
    "    #vec = args.vectors\n",
    "\n",
    "    # vectors file\n",
    "    embeddings_path = \"arabic-news.bin\"\n",
    "    # dataset file\n",
    "    dataset_path =  \"datasets/Aziz/datasets/astd-artwitter.csv\"\n",
    "\n",
    "    # run\n",
    "    ArSentiment(train, test, embeddings_path, dataset_path, plot_roc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3477 samples, validate on 387 samples\n",
      "Epoch 1/30\n",
      "3477/3477 [==============================] - 10s 3ms/step - loss: 0.6655 - acc: 0.6175 - val_loss: 0.5943 - val_acc: 0.6951\n",
      "Epoch 2/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.4023 - acc: 0.8332 - val_loss: 0.4918 - val_acc: 0.7674\n",
      "Epoch 3/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.1837 - acc: 0.9344 - val_loss: 0.6019 - val_acc: 0.7674\n",
      "Epoch 4/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.1034 - acc: 0.9635 - val_loss: 0.6702 - val_acc: 0.7674\n",
      "Epoch 5/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0756 - acc: 0.9715 - val_loss: 0.8677 - val_acc: 0.7649\n",
      "Epoch 6/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0601 - acc: 0.9796 - val_loss: 0.8405 - val_acc: 0.7545\n",
      "Epoch 7/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0509 - acc: 0.9825 - val_loss: 0.9845 - val_acc: 0.7519\n",
      "Epoch 8/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0451 - acc: 0.9825 - val_loss: 0.9889 - val_acc: 0.7597\n",
      "Epoch 9/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0405 - acc: 0.9848 - val_loss: 1.1941 - val_acc: 0.7519\n",
      "Epoch 10/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0461 - acc: 0.9819 - val_loss: 1.0904 - val_acc: 0.7804\n",
      "Epoch 11/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0329 - acc: 0.9873 - val_loss: 1.2068 - val_acc: 0.7623\n",
      "Epoch 12/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0323 - acc: 0.9856 - val_loss: 1.1652 - val_acc: 0.7597\n",
      "Epoch 13/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0333 - acc: 0.9865 - val_loss: 1.2130 - val_acc: 0.7597\n",
      "Epoch 14/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0314 - acc: 0.9833 - val_loss: 1.1764 - val_acc: 0.7726\n",
      "Epoch 15/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0268 - acc: 0.9885 - val_loss: 1.2586 - val_acc: 0.7674\n",
      "Epoch 16/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0258 - acc: 0.9894 - val_loss: 1.4097 - val_acc: 0.7674\n",
      "Epoch 17/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0252 - acc: 0.9905 - val_loss: 1.4878 - val_acc: 0.7649\n",
      "Epoch 18/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0259 - acc: 0.9868 - val_loss: 1.3342 - val_acc: 0.7649\n",
      "Epoch 19/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0249 - acc: 0.9873 - val_loss: 1.3584 - val_acc: 0.7597\n",
      "Epoch 20/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0245 - acc: 0.9891 - val_loss: 1.4909 - val_acc: 0.7623\n",
      "Epoch 21/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0202 - acc: 0.9902 - val_loss: 1.4984 - val_acc: 0.7545\n",
      "Epoch 22/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0220 - acc: 0.9894 - val_loss: 1.5701 - val_acc: 0.7597\n",
      "Epoch 23/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0228 - acc: 0.9888 - val_loss: 1.6207 - val_acc: 0.7623\n",
      "Epoch 24/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0211 - acc: 0.9902 - val_loss: 1.6630 - val_acc: 0.7571\n",
      "Epoch 25/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0199 - acc: 0.9914 - val_loss: 1.7338 - val_acc: 0.7468\n",
      "Epoch 26/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0198 - acc: 0.9899 - val_loss: 1.7405 - val_acc: 0.7519\n",
      "Epoch 27/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0201 - acc: 0.9896 - val_loss: 1.8518 - val_acc: 0.7468\n",
      "Epoch 28/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0196 - acc: 0.9902 - val_loss: 1.8343 - val_acc: 0.7597\n",
      "Epoch 29/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0212 - acc: 0.9879 - val_loss: 1.6743 - val_acc: 0.7623\n",
      "Epoch 30/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0196 - acc: 0.9885 - val_loss: 1.6983 - val_acc: 0.7623\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "def get_stop_words():\n",
    "    path = \"Arabic_stop_word.txt\"\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "\n",
    "def list_seq(train, test):\n",
    "    stop_words = get_stop_words()\n",
    "    list_sentences_train = train[\"txt\"]\n",
    "    list_sentences_test = test[\"txt\"]\n",
    "    max_features = 8000\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "    list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "    list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "    return list_tokenized_train, list_tokenized_test\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracy1(X_test, y_test):\n",
    "        # F1 score\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred=y_pred.round()\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"macc, f1_score, precision, recall\", results)\n",
    "\n",
    "\n",
    "def model_history(train, test,list_tokenized_train, list_tokenized_test, epochs, batch_size):\n",
    "    list_classes = [\"sentiment\"]\n",
    "    y = train['sentiment']\n",
    "    maxlen = 85 # you can tune\n",
    "    X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "    X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "    inp = Input(shape=(maxlen, )) \n",
    "    max_features = 8000\n",
    "\n",
    "    embed_size = 300 #you can tune\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = LSTM(30, return_sequences=True,name='lstm_layer')(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    history=model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    return history, model, X_te\n",
    "\n",
    "\n",
    "list_tokenized_train, list_tokenized_test=list_seq(train, test)\n",
    "    #word_dis(list_tokenized_train)\n",
    "history, model, X_te= model_history(train, test,list_tokenized_train, list_tokenized_test,30,32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macc, f1_score, precision, recall [0.7813953488372093, 0.781011615811373, 0.7718446601941746, 0.7718446601941747, 0.7718446601941747]\n"
     ]
    }
   ],
   "source": [
    "y_true = test['sentiment']\n",
    "calculate_accuracy1(X_te, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def clean(df):\n",
    "        path = \"Arabic_stop_word.txt\"\n",
    "        stop_words = []\n",
    "        with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "            stop_words = myfile.readlines()\n",
    "        stop_words = [word.strip() for word in stop_words]\n",
    "        arabic_punctuations = '''؛<>_()*،&^%][ـ،/:\"؟ـ`÷×.,'{}~¦+|!”…“–_'''\n",
    "        arabic_numbers = '''۰۱۲۳٤٥٦٧۸۹'''\n",
    "        english_punctuations = string.punctuation\n",
    "        punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "        arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "        for comments in df:\n",
    "            # removearabic_diacritics\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(arabic_diacritics,'',str(x)))\n",
    "\n",
    "            #def normalize_arabic(text)\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"[إأآا]\", \"ا\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ؤ\", \"ء\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ى\", \"ي\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ئ\", \"ء\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ة\", \"ه\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"گ\", \"ك\",str(x)))\n",
    "\n",
    "            \n",
    "\n",
    "            #def remove_punctuations(text):\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"[\"+punctuations_list+\"]\",'',str(x)))\n",
    "\n",
    "            # remove_repeating_char(text):\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(r'(.)\\1+', r'\\1', str(x)))\n",
    "            # remove '\\\\n'\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "\n",
    "            # remove any text starting with User... \n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "\n",
    "            # remove IP addresses or user IDs\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "\n",
    "            # lower uppercase letters\n",
    "            #df['txt'] = df['txt'].map(lambda x: str(x).lower())\n",
    "\n",
    "            #remove http links in the text\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"(http://.*?\\s)|(http://.*)\",'',str(x)))\n",
    "\n",
    "            #remove all punctuation\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"_\", '',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"«\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"»\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"“\", ' ',str(x))) \n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"”\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"😞\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"😔\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"😂\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"🌹\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"✨\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"👉\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"👈\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"☹\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"👇\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ک\", 'ك',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"—\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ლ\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"╹\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"◡\", ' ',str(x)))\n",
    "            \n",
    "            \n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"♥\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"♡\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"¥\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"؟\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"!\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"#\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"$\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"%\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"&\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"✖\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ة', 'ه',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(' ئ', 'ء',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ؤ', 'ء',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ے', 'ك',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ڪ', 'ك',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('أ', 'ا',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('إ', 'ا',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('آ', 'ا',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('\\\\r',' ',str(x)))\n",
    "            df['txt']= df['txt'].map(lambda x: re.sub(\"[\"+string.punctuation+\"]\",'',str(x)))\n",
    "            df['txt']= df['txt'].map(lambda x: re.sub(\"[\"+arabic_numbers+\"]\",'',str(x)))\n",
    "            df['txt']= df['txt'].map(lambda x: re.sub(\"[\"+punctuations_list+\"]\",'',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"[\"+digits+\"]\",'',str(x)))\n",
    "            #df['txt'] = df['txt'].map(lambda x: re.sub(r'[^\\x600-\\x6ff]','',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(r'[a-zA-Z?]','',str(x))) \n",
    "            df['txt'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "        return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
